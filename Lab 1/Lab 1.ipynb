{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "import re"
      ],
      "metadata": {
        "id": "wEgOknGaF_7T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the top 25 most frequent non-stopword words in a corpus\n",
        "def top_25(cp,sw):\n",
        "    # Removing the stopwords from the corpus\n",
        "    filtered_words = [word  for word in cp if word not in sw]\n",
        "\n",
        "    # Count the frequency of each word\n",
        "    word_count = Counter(filtered_words)\n",
        "\n",
        "    # Obtaining the top 25 most common words\n",
        "    top_25_words = word_count.most_common(25)\n",
        "\n",
        "    return top_25_words\n",
        "\n",
        "def preprocess(cp, sw):\n",
        "  # Add specific words of the poem as stopwords\n",
        "  sw.update(['thee', 'thou', 'thy', 'er', 'thel'])\n",
        "\n",
        "  # Preprocess the words of the poem using these steps:\n",
        "  # 1. Convert words to lowercase\n",
        "  # 2. Removing the non-alphabetical characters using regex library\n",
        "  updated_cp =  [str(item).lower() for item in cp]\n",
        "  updated_cp = re.findall(r'\\b[a-z]+\\b', ' '.join(updated_cp))\n",
        "\n",
        "  return updated_cp, sw"
      ],
      "metadata": {
        "id": "cU5jViGOF5zh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the required datasets from the corpus\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n",
        "# Load the words from the 'blake-poems.txt'\n",
        "cp = nltk.corpus.gutenberg.words('blake-poems.txt')\n",
        "# Load the stopwords\n",
        "sw = set(nltk.corpus.stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-WDPbV7GCmS",
        "outputId": "c3463d0b-5a42-4aff-b258-69f1eae38acc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_25(cp,sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zJG3sBuGHLz",
        "outputId": "e62f73ea-fe09-4b9a-d4b0-910ba1ba678c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 680),\n",
              " ('.', 201),\n",
              " ('And', 176),\n",
              " ('I', 130),\n",
              " (\"'\", 104),\n",
              " (';', 98),\n",
              " (':', 75),\n",
              " ('?', 65),\n",
              " ('The', 61),\n",
              " ('!', 59),\n",
              " ('\"', 51),\n",
              " ('thee', 42),\n",
              " ('like', 29),\n",
              " ('thy', 28),\n",
              " ('thou', 28),\n",
              " ('THE', 27),\n",
              " ('little', 26),\n",
              " ('In', 25),\n",
              " ('night', 25),\n",
              " ('away', 24),\n",
              " ('But', 24),\n",
              " ('Then', 23),\n",
              " ('joy', 22),\n",
              " ('He', 21),\n",
              " ('weep', 21)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we did not use preprocessing yet, the code resulted in a list containing punctuations, non word characters and duplicates ( \"THE\" and \"The\")"
      ],
      "metadata": {
        "id": "QN0D-xfDGXdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "updated_cp, sw = preprocess(cp, sw)\n",
        "top_25(updated_cp,sw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQZKzDkkG-dH",
        "outputId": "55d640aa-a273-4655-83ea-5675829600ba"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('little', 45),\n",
              " ('like', 35),\n",
              " ('love', 29),\n",
              " ('sweet', 28),\n",
              " ('night', 28),\n",
              " ('joy', 25),\n",
              " ('away', 24),\n",
              " ('weep', 24),\n",
              " ('father', 22),\n",
              " ('sleep', 21),\n",
              " ('happy', 19),\n",
              " ('shall', 19),\n",
              " ('day', 19),\n",
              " ('mother', 19),\n",
              " ('child', 18),\n",
              " ('every', 17),\n",
              " ('never', 17),\n",
              " ('hear', 16),\n",
              " ('green', 16),\n",
              " ('voice', 16),\n",
              " ('infant', 16),\n",
              " ('see', 16),\n",
              " ('human', 16),\n",
              " ('cloud', 15),\n",
              " ('lamb', 15)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the preprocessing, we have obtained a newly updated list of stopwords (containing synonyms), eliminated non word characters and possible duplicates due to case insensitive matching"
      ],
      "metadata": {
        "id": "QVH1r9MGHAkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusions\n",
        "1. This poem contains several Old English words whose meaning is the same with some words from stopwords so we thought that it is better to remove them.\n",
        "2. We have used list comprehension  since they are more efficent than writing nested for loops. It is also more\n",
        "memory efficient since they avoid the overhead of multiple variables.\n",
        "3. Before finding the most common words we did some text pre-processing to retain only meaningful words.\n",
        "4. In order to make the count process fast and efficent we have used the built-in functionality Counter. Since it also contains the function .most_common\n",
        "to find the most frequent words we avoided the loop through the words, sorting in descending order and then print 25 of them.( we also have a less efficient code below in case the built in functionality of the Counter is not allowed)"
      ],
      "metadata": {
        "id": "5y40y062H9jo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Less efficient solution without using built in functions\n",
        "#def top_25(our_text,sw):\n",
        "#  result = {}\n",
        "#  for i in our_text:\n",
        "#      if i not in sw:\n",
        "#          if i not in result.keys():\n",
        "#              result[i] = 1\n",
        "#          else:\n",
        "#              result[i] = result[i]+1\n",
        "#  result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True)[:25])\n",
        "#  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "gWJIfRzL5qSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}